{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ff0759-c381-499f-91da-27517f1933d3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28218902-cfd1-446c-ac98-7c0e0576d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import inspect\n",
    "from copy import deepcopy\n",
    "from copy import copy\n",
    "from datetime import datetime\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04326262-cd68-4245-a20d-553854b0749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer imports\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from datasets import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "298082cc-e525-4e53-b861-b3313a6b1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "sys.path.insert(0, '..')\n",
    "from visualization.visualization_utils import *\n",
    "\n",
    "sys.path.insert(0, '../DSL')\n",
    "from dsl import *\n",
    "from constants import *\n",
    "from solver_class import Solver\n",
    "import solvers\n",
    "import verifiers\n",
    "import verifiers_reformatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f849298b-4906-415e-85c4-6eb9602a6861",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac830af-43aa-4614-976e-a29921b8fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 20\n",
    "num_re_arc_examples_per_task_per_epoch = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8f9af0-6b28-463b-926b-c3241a422d7b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe86d7b2-b843-42a6-adf8-0fb5e9a80abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data')\n",
    "train_path = data_path / 'arc-agi_training_challenges.json'\n",
    "train_sols_path = data_path / 'arc-agi_training_solutions.json'\n",
    "eval_path = data_path / 'arc-agi_evaluation_challenges.json'\n",
    "eval_sols_path = data_path / 'arc-agi_evaluation_solutions.json'\n",
    "re_arc_path = data_path / 're-arc_tasks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8522c4ca-209c-4c6f-80e8-54d76a764c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, 'r') as f:\n",
    "    train_tasks = json.load(f)\n",
    "with open(train_sols_path, 'r') as f:\n",
    "    train_sols = json.load(f)\n",
    "\n",
    "train_task_labels = sorted(train_tasks.keys())\n",
    "\n",
    "#with open(eval_path, 'r') as f:\n",
    "#    eval_tasks = json.load(f)\n",
    "#with open(eval_sols_path, 'r') as f:\n",
    "#    eval_sols = json.load(f)\n",
    "\n",
    "#eval_task_labels = sorted(eval_tasks.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7c848d9-3548-4a30-bca7-1eb29d81d7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de600aea-c8fb-4da4-a578-26ee8dee1f7f",
   "metadata": {},
   "source": [
    "## Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c68f39d-2ff4-4ed2-b89f-cdd67df40dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "codegen_tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350M-mono\",\n",
    "                                                 #padding_side='left', # For padding batches of input in decoder-only context\n",
    "                                                 clean_up_tokenization_spaces = True,\n",
    "                                                 )\n",
    "codegen = AutoModelForCausalLM.from_pretrained(\"Salesforce/codegen-350M-mono\")\n",
    "codegen = codegen.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bcd49bd-50eb-4104-8de7-6ea2bf7fea1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EOS_TOKEN = codegen_tokenizer.eos_token\n",
    "BOS_TOKEN = codegen_tokenizer.bos_token\n",
    "codegen_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "#codegen_tokenizer.pad_token = codegen_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f740c03f-7ccf-44b1-bf59-dff54c9ddf59",
   "metadata": {},
   "source": [
    "## Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0763ff4-49d5-4f67-abeb-e74f329712a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Hodel's solvers and verifiers.\n",
    "# Verifiers are reformatted to look the same as the solvers.\n",
    "solver_programs = {label: Solver(inspect.getsource(getattr(solvers, f\"solve_{label}\"))) for label in train_task_labels}\n",
    "verifier_programs = {label: Solver(inspect.getsource(getattr(verifiers_reformatted, f\"solve_{label}\"))) for label in train_task_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c546dbb-e9be-4ae7-ab6e-9861a057c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Refactor to utilities file\n",
    "\n",
    "def grid_to_string(grid):\n",
    "    \"\"\"\n",
    "    Simply converts grid to string and removes whitespace.\n",
    "    A 30-by-30 grid will use ~1800 tokens.\n",
    "    \"\"\"\n",
    "    return str(grid).replace(\" \", \"\")\n",
    "\n",
    "def grid_to_string_compact(grid):\n",
    "    \"\"\"\n",
    "    Rows as strings of characters separated by linebreaks.\n",
    "    Uses approximately 4-times fewer tokens than grid_to_string.\n",
    "    \"\"\"\n",
    "    return \"\\n\".join([\"\".join([str(entry) for entry in row]) for row in grid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8943d1e9-8f5a-440f-94a1-e5a10f1e205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_random_re_arc_pairs(label: str, n: int) -> list[dict]:\n",
    "    with open(re_arc_path / f\"{label}.json\", \"r\") as f:\n",
    "        re_arc_examples = json.load(f)\n",
    "    return random.sample(re_arc_examples, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11663988-348f-4246-be22-0db6481c6e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_example(solver: Solver, in_grid, out_grid, compact = True) -> str:\n",
    "    \"\"\"\n",
    "    No more than 1600 tokens needed in worst case to encode a training example,\n",
    "    assuming compact = True\n",
    "    \"\"\"\n",
    "    in_grid_str = grid_to_string_compact(in_grid) if compact else grid_to_string(in_grid)\n",
    "    out_grid_str = grid_to_string_compact(out_grid) if compact else grid_to_string(out_grid)\n",
    "\n",
    "    docstring = f\"\"\"\n",
    "    Example input:\n",
    "    {in_grid_str}\n",
    "    Example output:\n",
    "    {out_grid_str}\n",
    "    \"\"\"\n",
    "    solver.update_docstring(docstring)\n",
    "    \n",
    "    solver_text = str(solver).strip()\n",
    "    return solver_text + EOS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c09a4d6-358d-4df7-9e7d-54be8b9cf7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913fb3ed\n",
      "\n",
      "def solve_913fb3ed(I):\n",
      "    \"\"\"\n",
      "    Example input:\n",
      "    000000000000\n",
      "    000000000000\n",
      "    000000000000\n",
      "    000000000000\n",
      "    000008000000\n",
      "    030000000000\n",
      "    000000002000\n",
      "    000000000000\n",
      "    000000000000\n",
      "    000000000000\n",
      "    000000000000\n",
      "    000000000000\n",
      "    Example output:\n",
      "    000000000000\n",
      "    000000000000\n",
      "    000000000000\n",
      "    000044400000\n",
      "    666048400000\n",
      "    636044411100\n",
      "    666000012100\n",
      "    000000011100\n",
      "    000000000000\n",
      "    000000000000\n",
      "    000000000000\n",
      "    000000000000\n",
      "    \"\"\"\n",
      "    x1 = ofcolor(I, THREE)\n",
      "    x2 = ofcolor(I, EIGHT)\n",
      "    x3 = ofcolor(I, TWO)\n",
      "    x4 = mapply(neighbors, x1)\n",
      "    x5 = mapply(neighbors, x2)\n",
      "    x6 = mapply(neighbors, x3)\n",
      "    x7 = fill(I, SIX, x4)\n",
      "    x8 = fill(x7, FOUR, x5)\n",
      "    O = fill(x8, ONE, x6)\n",
      "    return O<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# Show an example\n",
    "l = random.choice(train_task_labels)\n",
    "print(l)\n",
    "print(\"\")\n",
    "in_grid = train_tasks[l]['train'][0]['input']\n",
    "out_grid = train_tasks[l]['train'][0]['output']\n",
    "solver = solver_programs[l]\n",
    "print(create_training_example(solver, in_grid, out_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3849f8ef-77fb-409c-8e96-a88bea387f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01172e2b3f134d39af9495b5ad1a8056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check worst case for number of tokens needed to encode an example\n",
    "max_tokens_needed = 0\n",
    "for label in tqdm(train_task_labels):\n",
    "    solver = solver_programs[l]\n",
    "    verifier = verifier_programs[l]\n",
    "    N = len(train_tasks[label]['train'])\n",
    "    M = len(train_tasks[label]['test'])\n",
    "    for i in range(N):\n",
    "        in_grid = train_tasks[label]['train'][i]['input']\n",
    "        out_grid = train_tasks[label]['train'][i]['output']\n",
    "        solver_ex = create_training_example(solver, in_grid, out_grid)\n",
    "        verifier_ex = create_training_example(verifier, in_grid, out_grid)\n",
    "        max_tokens_needed = max(max_tokens_needed, len(codegen_tokenizer.tokenize(solver_ex)))\n",
    "        max_tokens_needed = max(max_tokens_needed, len(codegen_tokenizer.tokenize(verifier_ex)))\n",
    "    for i in range(M):\n",
    "        in_grid = train_tasks[label]['test'][i]['input']\n",
    "        out_grid = train_sols[label][i]\n",
    "        solver_ex = create_training_example(solver, in_grid, out_grid)\n",
    "        verifier_ex = create_training_example(verifier, in_grid, out_grid)\n",
    "        max_tokens_needed = max(max_tokens_needed, len(codegen_tokenizer.tokenize(solver_ex)))\n",
    "        max_tokens_needed = max(max_tokens_needed, len(codegen_tokenizer.tokenize(verifier_ex)))\n",
    "    with open(re_arc_path / f\"{label}.json\") as f:\n",
    "        re_arc_pairs = json.load(f)\n",
    "        for pair in re_arc_pairs:\n",
    "            in_grid = pair['input']\n",
    "            out_grid = pair['output']\n",
    "            solver_ex = create_training_example(solver, in_grid, out_grid)\n",
    "            verifier_ex = create_training_example(verifier, in_grid, out_grid)\n",
    "            max_tokens_needed = max(max_tokens_needed, len(codegen_tokenizer.tokenize(solver_ex)))\n",
    "            max_tokens_needed = max(max_tokens_needed, len(codegen_tokenizer.tokenize(verifier_ex)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffc2736f-b587-4727-a5bb-a839bba381a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of tokens needed for training examples: 1225\n"
     ]
    }
   ],
   "source": [
    "print(f\"Maximum number of tokens needed for training examples: {max_tokens_needed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a939a545-2426-4799-ae0a-d8f6f1f17849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find a way to sample different re-arc examples every epoch\n",
    "# TODO: Change the function names during training.\n",
    "\n",
    "training_examples = []\n",
    "\n",
    "for label in train_task_labels:\n",
    "    N = len(train_tasks[label]['train'])\n",
    "    M = len(train_tasks[label]['test'])\n",
    "    \n",
    "    solver = solver_programs[label]\n",
    "    verifier = verifier_programs[label]\n",
    "\n",
    "    # Create solver examples from ordinary arc tasks\n",
    "    for i in range(N):\n",
    "        in_grid = train_tasks[label]['train'][i]['input']\n",
    "        out_grid = train_tasks[label]['train'][i]['output']\n",
    "        solver_ex = create_training_example(solver, in_grid, out_grid)\n",
    "        training_examples.append(solver_ex)\n",
    "    for i in range(M):\n",
    "        in_grid = train_tasks[label]['test'][i]['input']\n",
    "        out_grid = train_sols[label][i]\n",
    "        solver_ex = create_training_example(solver, in_grid, out_grid)\n",
    "        training_examples.append(solver_ex)\n",
    "\n",
    "    # Create verifier examples from re-arc tasks\n",
    "    with open(re_arc_path / f\"{label}.json\") as f:\n",
    "        re_arc_pairs = json.load(f)\n",
    "    re_arc_pairs = random.sample(re_arc_pairs, k = num_re_arc_examples_per_task_per_epoch)\n",
    "    for pair in re_arc_pairs:\n",
    "        in_grid = pair['input']\n",
    "        out_grid = pair['output'] \n",
    "        verifier_ex = create_training_example(verifier, in_grid, out_grid)\n",
    "        training_examples.append(verifier_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dffb1348-3748-4ab6-b48e-bee52b2f5f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 9718 training examples, an average of 24.295 per task.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have {len(training_examples)} training examples, an average of {len(training_examples) / 400} per task.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26f3ef2d-0621-4eda-8d2a-01251f34dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict({'text': training_examples})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4179c028-5b95-4215-a943-e2ddfadb0bc0",
   "metadata": {},
   "source": [
    "## Train and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f06064b-f2e8-4e39-9014-6c5b03984c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17cc1082412f4da8b0fff3712ab857e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = codegen,\n",
    "    tokenizer = codegen_tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    args = SFTConfig(\n",
    "        per_device_train_batch_size = 1,\n",
    "        gradient_accumulation_steps = 8,\n",
    "        dataset_text_field = \"text\",\n",
    "        max_seq_length = min(max_tokens_needed + 3, 1565), # 2048 is took big, OOM\n",
    "        num_train_epochs = num_train_epochs,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = True,\n",
    "        bf16 = False,\n",
    "        logging_steps = 400,\n",
    "        save_steps = 1000,\n",
    "        optim = \"adamw_torch\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fb3cca0-77fc-4584-9122-ff9c887196b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24280' max='24280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24280/24280 3:53:00, Epoch 19/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.812200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.598900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.544200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.486600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.470900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.466000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.412100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.413000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.363200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.359500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.373200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.318000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.315500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.309000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.258100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.247100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.258800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.197100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.197700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.203300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.157400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.143700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.149700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.106900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.112100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.091100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.080800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.086200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.071200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.063200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.067200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.058500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.050100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.053600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>0.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>0.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>0.044100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.040700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16400</td>\n",
       "      <td>0.037900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>0.037700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17200</td>\n",
       "      <td>0.036200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17600</td>\n",
       "      <td>0.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.034400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18400</td>\n",
       "      <td>0.032300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18800</td>\n",
       "      <td>0.031200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19200</td>\n",
       "      <td>0.031500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19600</td>\n",
       "      <td>0.030300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.029400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20400</td>\n",
       "      <td>0.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20800</td>\n",
       "      <td>0.028700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21200</td>\n",
       "      <td>0.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21600</td>\n",
       "      <td>0.028900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.027200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22400</td>\n",
       "      <td>0.026700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22800</td>\n",
       "      <td>0.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23200</td>\n",
       "      <td>0.026100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23600</td>\n",
       "      <td>0.025400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.025500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=24280, training_loss=0.1685530012089888, metrics={'train_runtime': 13981.7077, 'train_samples_per_second': 13.901, 'train_steps_per_second': 1.737, 'total_flos': 1.9682718977989018e+17, 'train_loss': 0.1685530012089888, 'epoch': 19.987651780201688})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
