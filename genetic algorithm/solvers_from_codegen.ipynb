{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccebc029-b2d0-4d2b-85b3-7f127deb0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import inspect\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from copy import deepcopy\n",
    "from copy import copy\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0497828a-82d5-468c-aa94-d711445376b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from datasets import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e01e5a4-fc29-4812-8f5e-065c755df81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data')\n",
    "train_path = data_path / 'arc-agi_training_challenges.json'\n",
    "train_sols_path = data_path / 'arc-agi_training_solutions.json'\n",
    "eval_path = data_path / 'arc-agi_evaluation_challenges.json'\n",
    "eval_sols_path = data_path / 'arc-agi_evaluation_solutions.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bbfa15b-9844-4f77-8be6-2502cb7d6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../DSL')\n",
    "\n",
    "from visualization.visualization_utils import *\n",
    "import solvers\n",
    "from solver_class import Solver\n",
    "from dsl import *\n",
    "from constants import *\n",
    "from fitness_scoring import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5b3c7d0-4c83-44f2-8319-4a9d394c01c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, 'r') as f:\n",
    "    train_tasks = json.load(f)\n",
    "with open(train_sols_path, 'r') as f:\n",
    "    train_sols = json.load(f)\n",
    "with open(eval_path, 'r') as f:\n",
    "    eval_tasks = json.load(f)\n",
    "with open(eval_sols_path, 'r') as f:\n",
    "    eval_sols = json.load(f)\n",
    "\n",
    "train_task_labels = sorted(train_tasks.keys())\n",
    "eval_task_labels = sorted(eval_tasks.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7e56531-5767-4c78-aae4-36475806394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ast = lambda g: tuple(tuple(r) for r in g) # Converts grid to tuple format for DSL\n",
    "\n",
    "# Convert all train and eval examples to tuples for DSL\n",
    "for train_label in train_task_labels:\n",
    "    num_train = len(train_tasks[train_label]['train']) \n",
    "    num_test = len(train_tasks[train_label]['test'])\n",
    "    for i in range(num_train):\n",
    "        train_tasks[train_label]['train'][i]['input'] = ast(train_tasks[train_label]['train'][i]['input'])\n",
    "        train_tasks[train_label]['train'][i]['output'] = ast(train_tasks[train_label]['train'][i]['output'])\n",
    "    for i in range(num_test):\n",
    "        train_tasks[train_label]['test'][i]['input'] = ast(train_tasks[train_label]['test'][i]['input'])\n",
    "        train_sols[train_label][i] = ast(train_sols[train_label][i])\n",
    "for eval_label in eval_task_labels:\n",
    "    num_train = len(eval_tasks[eval_label]['train']) \n",
    "    num_test = len(eval_tasks[eval_label]['test'])\n",
    "    for i in range(num_train):\n",
    "        eval_tasks[eval_label]['train'][i]['input'] = ast(eval_tasks[eval_label]['train'][i]['input'])\n",
    "        eval_tasks[eval_label]['train'][i]['output'] = ast(eval_tasks[eval_label]['train'][i]['output'])\n",
    "    for i in range(num_test):\n",
    "        eval_tasks[eval_label]['test'][i]['input'] = ast(eval_tasks[eval_label]['test'][i]['input'])\n",
    "        eval_sols[eval_label][i] = ast(eval_sols[eval_label][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dcd1319-f1c9-427e-988b-0208ff6e6e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f3e0e9-21c6-4d88-bae7-e7c2a1f2b635",
   "metadata": {},
   "source": [
    "# Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "967ff0c8-cbac-4560-a5f3-c6dc93fb19ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "codegen_tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350M-mono\",\n",
    "                                                 padding_side='left', # For padding batches of input in decoder-only context\n",
    "                                                 clean_up_tokenization_spaces = True,\n",
    "                                                 #torch_dtype=torch.float16, # For quantization; TODO figure out how this works\n",
    "                                                 ) \n",
    "codegen = AutoModelForCausalLM.from_pretrained(\"../CodeGen fine-tuning/outputs/v5/\",\n",
    "                                              #torch_dtype=torch.float16, # For quantization; TODO figure out how this works\n",
    "                                              )\n",
    "codegen = codegen.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efc6f885-a01b-4b52-926b-da3904059bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_TOKEN = codegen_tokenizer.eos_token\n",
    "BOS_TOKEN = codegen_tokenizer.bos_token\n",
    "codegen_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "PAD_TOKEN = '[PAD]'\n",
    "#codegen_tokenizer.pad_token = codegen_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4a4758-4fd5-4bd5-b720-3dcd32a60b87",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4092cbf8-64f7-4f4c-af84-383f2f76abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_to_string(grid):\n",
    "    \"\"\"\n",
    "    Simply converts grid to string and removes whitespace.\n",
    "    A 30-by-30 grid will use ~1800 tokens.\n",
    "    \"\"\"\n",
    "    return str(grid).replace(\" \", \"\")\n",
    "\n",
    "def grid_to_string_compact(grid):\n",
    "    \"\"\"\n",
    "    Rows as strings of characters separated by linebreaks.\n",
    "    Uses approximately 4-times fewer tokens than grid_to_string.\n",
    "    \"\"\"\n",
    "    return \"\\n\".join([\"\".join([str(entry) for entry in row]) for row in grid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ef7c558-dfd1-4509-8d16-785dd81c8e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generation_prompt(in_grid, out_grid, label = None):\n",
    "    if label == None:\n",
    "        label = random_label()\n",
    "    result = f'''def solve_{label}(I):\n",
    "    \"\"\"\n",
    "    Example input:\n",
    "    {\"\\n    \".join(grid_to_string_compact(in_grid).split(\"\\n\"))}\n",
    "    Example output:\n",
    "    {\"\\n    \".join(grid_to_string_compact(out_grid).split(\"\\n\"))}\n",
    "    \"\"\"\n",
    "    '''\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2064ad43-78f1-48ac-9a75-5def4f0179d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_label() -> str:\n",
    "    \"\"\"\n",
    "    Random task label consisting of 8 hexidecimal digits lowercase.\n",
    "    \"\"\"\n",
    "    digits = list(\"0123456789abcdef\")\n",
    "    return \"\".join([random.choice(digits) for _ in range(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4692011d-6653-4b86-9712-14b28fba4029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_grid(rows = None, cols = None, palette = None):\n",
    "    if not rows:\n",
    "        rows = random.randint(1,30)\n",
    "    if not cols:\n",
    "        cols = random.randint(1,30)\n",
    "    if not palette:\n",
    "        palette = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    return tuple(tuple(random.choice(palette) for _ in range(cols)) for _ in range(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "771b2714-b77f-45d1-9837-ce151b240a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidate_solvers(model, tokenizer, in_out_pairs, generate_args = {'max_new_tokens': 512}, min_num_solvers = 100):\n",
    "    candidates = []\n",
    "    prompts = []\n",
    "\n",
    "    while len(prompts) < min_num_solvers:\n",
    "        prompts.extend([create_generation_prompt(pair['input'], pair['output']) for pair in in_out_pairs])\n",
    "    \n",
    "    for i in range((len(prompts)-1) // MAX_BATCH_SIZE + 1):  \n",
    "        inputs = tokenizer(prompts[i*MAX_BATCH_SIZE : (i+1)*MAX_BATCH_SIZE],\n",
    "                           padding = True,\n",
    "                           return_tensors = 'pt',\n",
    "                          ).to(DEVICE)\n",
    "        outputs = model.generate(**inputs,\n",
    "                                 pad_token_id = tokenizer.eos_token_id,\n",
    "                                **generate_args,\n",
    "                                )\n",
    "\n",
    "        candidates.extend(tokenizer.batch_decode(outputs))\n",
    "\n",
    "    return candidates\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8116dc64-63e4-43ab-a1f4-74901a3c3603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_candidate(candidate: str) -> str:\n",
    "    candidate = candidate.replace(EOS_TOKEN, \"\")\n",
    "    candidate = candidate.replace(BOS_TOKEN, \"\")\n",
    "    candidate = candidate.replace(PAD_TOKEN, \"\")\n",
    "    if \"return O\" not in candidate:\n",
    "        return None\n",
    "    return candidate.split(\"return O\")[0] + \"return O\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32084ce5-2152-4040-955c-897111b12cca",
   "metadata": {},
   "source": [
    "# Generate solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e0dc265-4380-431e-8e30-7c9046edee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Got OOM on iteration 60/400 using batchsize 32, after 5hr 30min, 1000 progs per task\n",
    "MAX_BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b4dd6b1-a138-4ebd-aa8e-cc30f44eb1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737c69c5065e4df8b8aed0081bbcedc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Fix this cell to give outputs in new log format\n",
    "\n",
    "full_scoring_results = {}\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "for i, label in enumerate(tqdm(eval_task_labels)):\n",
    "    pairs = eval_tasks[label]['train']\n",
    "    \n",
    "    generate_args = {\n",
    "        'max_new_tokens': 512,\n",
    "        'do_sample': True,\n",
    "        'temperature': 2.0,\n",
    "        'top_k': 50,\n",
    "        #'num_beams': 2, # Using multiple beams creates too much memory pressure\n",
    "    }\n",
    "\n",
    "    candidates = generate_candidate_solvers(codegen, codegen_tokenizer, pairs, generate_args = generate_args, min_num_solvers = 200)\n",
    "    candidates = [clean_candidate(c) for c in candidates]\n",
    "    programs = []\n",
    "    for c in candidates:\n",
    "        try:\n",
    "            programs.append(Solver(c))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # TODO: Right now candidate solvers generate random names. Fix this to avoid potential collisions in dictionary\n",
    "    scoring_results = score_solvers_vs_tasks(programs, pairs, scoring_functions, solver_timeout = 1.0)\n",
    "    scoring_results = {solver_name: score if score != None else 1.0 for solver_name, score in scoring_results.items()}\n",
    "\n",
    "    if False:\n",
    "        print(f\"Completed task {i}, {label}.\")\n",
    "        print(f\"Valid programs: {len(programs)}\")\n",
    "        print(f\"Valid scores: {sum([(score < 1.0) for score in scoring_results.values()])}\")\n",
    "        print(f\"Best score: {min(scoring_results.values())}\")\n",
    "        print(f\"Time elapsed: {(time.time()-starttime):.2f} seconds\")\n",
    "        print(\"\")\n",
    "\n",
    "    full_scoring_results[label] = sorted(scoring_results.items(), key = lambda x: x[1])\n",
    "\n",
    "    # Save results after every task\n",
    "    sorted_scoring_results = sorted(full_scoring_results.items(), key = lambda x: [x[1][i][1] for i in range(len(x[1]))])\n",
    "\n",
    "    with open('v5_solvers_vs_eval2_part2.json', 'w') as f:\n",
    "        f.seek(0)\n",
    "        json.dump(sorted_scoring_results, f, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06ec74a-1467-4e73-b285-18a83c176479",
   "metadata": {},
   "source": [
    "# Experimentation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7c78ef9-42ff-44c7-99bf-b82d457da519",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_labels = ['d56f2372', '1e97544e', '3490cc26', 'bf699163', '2037f2c7']\n",
    "MAX_BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cd6e4e6-1bff-43c1-aa67-dd69605ceec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_and_log_experiment(labels, \n",
    "                               model,\n",
    "                               tokenizer,\n",
    "                               solvers_per_task = 64,\n",
    "                               generate_args = {\n",
    "                                    'max_new_tokens': 512,\n",
    "                                    'do_sample': True,\n",
    "                                    'top_k': 50,\n",
    "                                    'temperature': 1.0,\n",
    "                               },\n",
    "                               log_file = 'log.json'\n",
    "                              ):\n",
    "    \"\"\"\n",
    "    Generate a bunch of solvers for each task according to parameters\n",
    "    given, then score them, then record the scores to log_file.\n",
    "\n",
    "    The log is a dict with labels as keys, and each entry is a list of\n",
    "    pairs (score, solver_text) sorted by score. A score of 1.1 indicates\n",
    "    that solver_text failed to compile to a program. A score of 1.0\n",
    "    almost surely indicates that solver_text compiled but failed to \n",
    "    run on one of the pairs. Any lower scores are computed as usual. The\n",
    "    solver texts should not include docstrings.\n",
    "    \"\"\"\n",
    "    results = {label: [] for label in labels}\n",
    "    \n",
    "    for label in tqdm(labels):\n",
    "        pairs = eval_tasks[label]['train']\n",
    "        results_this_round = []\n",
    "        \n",
    "        # Generate candidate solvers\n",
    "        candidates = generate_candidate_solvers(model, tokenizer, pairs, generate_args = generate_args, min_num_solvers = solvers_per_task)\n",
    "        candidates = candidates[:solvers_per_task]\n",
    "\n",
    "        # Clean up candidates\n",
    "        cleaned_candidates = []\n",
    "        for c in candidates:\n",
    "            cleaned = clean_candidate(c)\n",
    "            if not cleaned:\n",
    "                results_this_round.append((1.1, c.replace(EOS_TOKEN, \"\").replace(BOS_TOKEN, \"\").replace(PAD_TOKEN, \"\")))\n",
    "            else:\n",
    "                cleaned_candidates.append(cleaned)\n",
    "\n",
    "        # Parse the candidates into programs\n",
    "        solvers = []\n",
    "        for c in cleaned_candidates:\n",
    "            try:\n",
    "                solvers.append(Solver(c))\n",
    "            except:\n",
    "                results_this_round.append((1.1, c))\n",
    "    \n",
    "        # Score the solvers\n",
    "        scoring_results = score_solvers_vs_tasks(solvers, pairs, scoring_functions, solver_timeout = 1.0)\n",
    "        scoring_results = [(score, solver.function_text) for score, solver in scoring_results]\n",
    "        results_this_round += scoring_results\n",
    "        \n",
    "        # Add results\n",
    "        results[label] = sorted(results_this_round, key = lambda x: x[0])\n",
    "    \n",
    "    # Log the results\n",
    "    with open(log_file, 'w') as f:\n",
    "        json.dump(results, f)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d178cf-ee7a-405b-814c-5d4c945a333f",
   "metadata": {},
   "source": [
    "### Experiment 4b, 10/26/2024: Totally random grids with higher temps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b794b08-3f72-4eea-801b-5855c6d0f6f6",
   "metadata": {},
   "source": [
    "Using parameters in experiment 4 gave ~330 unique solvers for each trial, which is lots of repetition out of 512 solvers. Here we turn up temp to 3.0 to look for more varied results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9be0b26-ed65-4dea-9e3d-065317dc3648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f535a10a37d483789edb23441bcc609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7ed3372d6b10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amzi/installs/miniforge3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "  File \"/home/amzi/installs/miniforge3/lib/python3.12/site-packages/timeout_decorator/timeout_decorator.py\", line 69, in handler\n",
      "    _raise_exception(timeout_exception, exception_message)\n",
      "  File \"/home/amzi/installs/miniforge3/lib/python3.12/site-packages/timeout_decorator/timeout_decorator.py\", line 45, in _raise_exception\n",
      "    raise exception()\n",
      "timeout_decorator.timeout_decorator.TimeoutError: 'Timed Out'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3394575069c943ecaf7f83757cc8abdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585a25b8fa704c4082f46df10c09e326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f72a6efce394cae9c0d9134e6cce045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165204998fb1427cb2d6149236e69176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4ee6713e5e4484875282b050defcd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48bab71497743e69741cc11614768cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dccb81c5139745a88aac104298d10c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7352d92a547745079e16b7fcbbf83eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f9c157d8ed42e19465789b0ce446a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_trials = 10\n",
    "\n",
    "solvers_per_task = 512\n",
    "generate_args = {\n",
    "    'max_new_tokens': 512,\n",
    "    'do_sample': True,\n",
    "    'top_k': 50,\n",
    "    'temperature': 3.0,\n",
    "}\n",
    "\n",
    "for trial in range(num_trials):\n",
    "    results = {label: [] for label in experiment_labels}\n",
    "    results_starter = []\n",
    "\n",
    "    # Generate random pairs to seed our solver generator\n",
    "    random_pairs = [{'input': random_grid(10, 10), 'output': random_grid(10, 10)} for _ in range(4)]\n",
    "    \n",
    "    # Generate candidate solvers\n",
    "    candidates = generate_candidate_solvers(codegen, \n",
    "                                            codegen_tokenizer,\n",
    "                                            random_pairs,\n",
    "                                            generate_args = generate_args, \n",
    "                                            min_num_solvers = solvers_per_task,\n",
    "                                           )\n",
    "    candidates = candidates[:solvers_per_task]\n",
    "\n",
    "    # Clean up candidates\n",
    "    cleaned_candidates = []\n",
    "    for c in candidates:\n",
    "        cleaned = clean_candidate(c)\n",
    "        if not cleaned:\n",
    "            results_starter.append((1.1, c.replace(EOS_TOKEN, \"\").replace(BOS_TOKEN, \"\").replace(PAD_TOKEN, \"\")))\n",
    "        else:\n",
    "            cleaned_candidates.append(cleaned)\n",
    "\n",
    "    # Parse the candidates into programs\n",
    "    solvers = []\n",
    "    for c in cleaned_candidates:\n",
    "        try:\n",
    "            solvers.append(Solver(c))\n",
    "        except:\n",
    "            results_starter.append((1.1, c))\n",
    "\n",
    "    # Now score our random solvers against each task\n",
    "    for label in tqdm(experiment_labels):\n",
    "        pairs = eval_tasks[label]['train']\n",
    "        results_this_round = deepcopy(results_starter)\n",
    "\n",
    "        # Score the solvers\n",
    "        scoring_results = score_solvers_vs_tasks(solvers, pairs, scoring_functions, solver_timeout = 1.0)\n",
    "        scoring_results = [(score, solver.function_text) for score, solver in scoring_results]\n",
    "        results_this_round += scoring_results\n",
    "        \n",
    "        # Add results\n",
    "        results[label] = sorted(results_this_round, key = lambda x: x[0])\n",
    "    \n",
    "    # Log the results\n",
    "    log_file = f\"fitness data/random grid experiments/trial{trial}_temp3.json\"\n",
    "    with open(log_file, 'w') as f:\n",
    "        json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfdc6ab-4213-4458-b0be-21fd7e9bce4b",
   "metadata": {},
   "source": [
    "### Experiment 4, 10/26/2024: What happens with programs generated via totally random grids?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd05e88-d34d-42ee-858c-e10380e17483",
   "metadata": {},
   "source": [
    "We use four pairs of 10x10 uniform random grids to generate 512 solvers, then run those solvers vs the tasks, for 10 trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aad44a48-0d5d-4607-a74f-a33da36e7c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8358059b28164fdc943557d61b1e2337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b780c8679514d65920ca540bab9f788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d7badde26f453abf5cb0f7a87a15af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9636ae39786745558485899e8b8acdbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7ed3372d6b10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amzi/installs/miniforge3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "  File \"/home/amzi/installs/miniforge3/lib/python3.12/site-packages/timeout_decorator/timeout_decorator.py\", line 69, in handler\n",
      "    _raise_exception(timeout_exception, exception_message)\n",
      "  File \"/home/amzi/installs/miniforge3/lib/python3.12/site-packages/timeout_decorator/timeout_decorator.py\", line 45, in _raise_exception\n",
      "    raise exception()\n",
      "timeout_decorator.timeout_decorator.TimeoutError: 'Timed Out'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec5ab9b1b8845c69a7745ee8b919685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848444607a714cbfa7c61cd6570a0e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea446ea7bc76494e82d1e36c77715ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4256ceb4540242b689cc04d29d96562c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c04d9cacb34464b3a54cba387ae420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708ab1ef9b5e4761b6a94abb57de6fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_trials = 10\n",
    "\n",
    "solvers_per_task = 512\n",
    "generate_args = {\n",
    "    'max_new_tokens': 512,\n",
    "    'do_sample': True,\n",
    "    'top_k': 50,\n",
    "    'temperature': 2.0,\n",
    "}\n",
    "\n",
    "for trial in range(num_trials):\n",
    "    results = {label: [] for label in experiment_labels}\n",
    "    results_starter = []\n",
    "\n",
    "    # Generate random pairs to seed our solver generator\n",
    "    random_pairs = [{'input': random_grid(10, 10), 'output': random_grid(10, 10)} for _ in range(4)]\n",
    "    \n",
    "    # Generate candidate solvers\n",
    "    candidates = generate_candidate_solvers(codegen, \n",
    "                                            codegen_tokenizer,\n",
    "                                            random_pairs,\n",
    "                                            generate_args = generate_args, \n",
    "                                            min_num_solvers = solvers_per_task,\n",
    "                                           )\n",
    "    candidates = candidates[:solvers_per_task]\n",
    "\n",
    "    # Clean up candidates\n",
    "    cleaned_candidates = []\n",
    "    for c in candidates:\n",
    "        cleaned = clean_candidate(c)\n",
    "        if not cleaned:\n",
    "            results_starter.append((1.1, c.replace(EOS_TOKEN, \"\").replace(BOS_TOKEN, \"\").replace(PAD_TOKEN, \"\")))\n",
    "        else:\n",
    "            cleaned_candidates.append(cleaned)\n",
    "\n",
    "    # Parse the candidates into programs\n",
    "    solvers = []\n",
    "    for c in cleaned_candidates:\n",
    "        try:\n",
    "            solvers.append(Solver(c))\n",
    "        except:\n",
    "            results_starter.append((1.1, c))\n",
    "\n",
    "    # Now score our random solvers against each task\n",
    "    for label in tqdm(experiment_labels):\n",
    "        pairs = eval_tasks[label]['train']\n",
    "        results_this_round = deepcopy(results_starter)\n",
    "\n",
    "        # Score the solvers\n",
    "        scoring_results = score_solvers_vs_tasks(solvers, pairs, scoring_functions, solver_timeout = 1.0)\n",
    "        scoring_results = [(score, solver.function_text) for score, solver in scoring_results]\n",
    "        results_this_round += scoring_results\n",
    "        \n",
    "        # Add results\n",
    "        results[label] = sorted(results_this_round, key = lambda x: x[0])\n",
    "    \n",
    "    # Log the results\n",
    "    log_file = f\"fitness data/random grid experiments/trial{trial}.json\"\n",
    "    with open(log_file, 'w') as f:\n",
    "        json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3acc95b-cd08-4f80-ace8-d81d551914fe",
   "metadata": {},
   "source": [
    "### Experiment 3, 10/26/2024: How does top_k affect results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fe8591-7fb3-443d-a3b7-2809ebbffc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ks = [2, 4, 8, 16, 32, 64, 128]\n",
    "for top_k in top_ks:\n",
    "    results = conduct_and_log_experiment(labels = experiment_labels,\n",
    "                                         model = codegen,\n",
    "                                         tokenizer = codegen_tokenizer,\n",
    "                                         solvers_per_task = 512,\n",
    "                                         generate_args = {\n",
    "                                                'max_new_tokens': 512,\n",
    "                                                'do_sample': True,\n",
    "                                                'top_k': top_k,\n",
    "                                                'temperature': 2.0,\n",
    "                                         },\n",
    "                                         log_file = f'fitness data/top_k experiments/{top_k}.json',\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fad838-accb-49e1-8dcf-6906c9a41694",
   "metadata": {},
   "source": [
    "### Experiment 2, 10/26/2024: How does number of solvers affect results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad34aca-c4c7-4fd2-aa70-bfd44e4d84a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_counts = [32, 64, 128, 256, 512, 1024, 2048]\n",
    "for num_solvers in solver_counts:\n",
    "    results = conduct_and_log_experiment(labels = experiment_labels,\n",
    "                                         model = codegen,\n",
    "                                         tokenizer = codegen_tokenizer,\n",
    "                                         solvers_per_task = num_solvers,\n",
    "                                         generate_args = {\n",
    "                                                'max_new_tokens': 512,\n",
    "                                                'do_sample': True,\n",
    "                                                'top_k': 50,\n",
    "                                                'temperature': 2.0,\n",
    "                                         },\n",
    "                                         log_file = f'fitness data/num_solvers experiments/{num_solvers}.json',\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f27738-e00e-4498-8a87-4b80125081e9",
   "metadata": {},
   "source": [
    "### Experiment 1, 10/25/2024: How does temperature affect results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff66fb5-3149-4d1d-a1a2-c266269c3a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for temp in [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]:\n",
    "    results = conduct_and_log_experiment(labels = experiment_labels,\n",
    "                                         model = codegen,\n",
    "                                         tokenizer = codegen_tokenizer,\n",
    "                                         solvers_per_task = 256,\n",
    "                                         generate_args = {\n",
    "                                                'max_new_tokens': 512,\n",
    "                                                'do_sample': True,\n",
    "                                                'top_k': 50,\n",
    "                                                'temperature': temp,\n",
    "                                         },\n",
    "                                         log_file = f'fitness data/temperature experiments/temp{temp}.json',\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7589b64-e703-45c5-a996-b703f3792390",
   "metadata": {},
   "source": [
    "# Scratch work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3bfc75-91d4-4e23-8149-7594c259a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoiding OOM on 25094a63, task at index 60\n",
    "l = eval_task_labels[60]\n",
    "print(l)\n",
    "in_out_pairs = eval_tasks[l]['train']\n",
    "prompts = []\n",
    "while len(prompts) < 200:\n",
    "        prompts.extend([create_generation_prompt(pair['input'], pair['output']) for pair in in_out_pairs])\n",
    "print(prompts[4])\n",
    "print(len(codegen_tokenizer.encode(prompts[0])))\n",
    "# Requires 900+ tokens to represent grids, which leads to OOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1dee6e7a-8dae-4c2d-910e-79382479b19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed candidates in 32.84 seconds\n"
     ]
    }
   ],
   "source": [
    "l = '009d5c81'\n",
    "l = eval_task_labels[4]\n",
    "\n",
    "pairs = eval_tasks[l]['train']\n",
    "#pairs = [{'input': random_grid(20, 20), 'output': random_grid(20, 20)} for i in range(3)]\n",
    "\n",
    "generate_args = {\n",
    "    'max_new_tokens': 512,\n",
    "    'do_sample': True,\n",
    "    'temperature': 0.5,\n",
    "    'top_k': 20,\n",
    "    #'num_beams': 2, # Using multiple beams creates too much memory pressure\n",
    "}\n",
    "\n",
    "starttime = time.time()\n",
    "cands = generate_candidate_solvers(codegen, codegen_tokenizer, pairs, generate_args = generate_args, min_num_solvers = 50)\n",
    "print(f\"Computed candidates in {(time.time()-starttime):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c381b45-dd2d-41f5-a947-31b39d0a251e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c6ab21ab-91eb-49ab-a4b9-30c4e563e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_cands = [clean_candidate(cand) for cand in cands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "275b7012-7d08-4701-8715-751c715b897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "progs = []\n",
    "for cand in cleaned_cands:\n",
    "    try:\n",
    "        progs.append(Solver(cand))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6c3910f8-d154-45b1-b03a-3ccb52ffdbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(progs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "85271360-f090-4f16-a894-b1315c02970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fitness_scoring import *\n",
    "       \n",
    "scores = score_solvers_vs_tasks(progs, pairs, scoring_functions, solver_timeout = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a4bb7e1-dcd7-48b6-833f-b27daa332e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09617932940310235,\n",
       " 0.10830729281693237,\n",
       " 0.12581017833567684,\n",
       " 0.12581017833567684,\n",
       " 0.12581017833567684,\n",
       " 0.1451198226642063,\n",
       " 0.2276676681134889,\n",
       " 0.24111676145747532,\n",
       " 0.25464015450133604,\n",
       " 0.26147469968565545,\n",
       " 0.26147469968565545,\n",
       " 0.26147469968565545,\n",
       " 0.26147469968565545,\n",
       " 0.26147469968565545,\n",
       " 0.2667732786862824,\n",
       " 0.29310876589370266,\n",
       " 0.3650276645492598,\n",
       " 0.36861214897799227,\n",
       " 0.4521855666908194,\n",
       " 0.5704644893874207,\n",
       " 0.5704644893874207,\n",
       " 0.5777334591509189,\n",
       " 0.6694927403348179,\n",
       " 0.6694927403348179,\n",
       " 0.7600000000000001,\n",
       " 0.7600000000000001,\n",
       " 0.7942041298228831,\n",
       " 0.9462068965517242,\n",
       " 0.9597777777777777]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_null_scores = [score for score in scores.values() if score != None]\n",
    "sorted(non_null_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "96401271-4b03-4c80-af69-98c155f7d72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_dict = {}\n",
    "for prog in progs:\n",
    "    if prog:\n",
    "        n = str(prog).split(\" \", 1)[1].split(\"(\")[0]\n",
    "        prog_dict[n] = prog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ffcd745-eb88-4c9e-8508-c43c686a88e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2276676681134889 \n",
      " def solve_b3cdade0(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = leastcolor(I)\n",
      "    x2 = ofcolor(I, x1)\n",
      "    x3 = shift(x2, NEG_UNITY)\n",
      "    x4 = recolor(THREE, x3)\n",
      "    x5 = shift(x2, UNITY)\n",
      "    x6 = recolor(SEVEN, x5)\n",
      "    x7 = shift(x2, DOWN_LEFT)\n",
      "    x8 = recolor(EIGHT, x7)\n",
      "    x9 = shift(x2, UP_RIGHT)\n",
      "    x10 = recolor(SIX, x9)\n",
      "    x11 = mostcolor(I)\n",
      "    x12 = fill(I, x11, x2)\n",
      "    x13 = combine(x4, x6)\n",
      "    x14 = combine(x8, x10)\n",
      "    x15 = combine(x13, x14)\n",
      "    O = paint(x12, x15)\n",
      "    return O\n",
      "\n",
      "0.1451198226642063 \n",
      " def solve_0388b7f2(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = objects(I, T, F, T)\n",
      "    x2 = colorfilter(x1, THREE)\n",
      "    x3 = colorfilter(x1, TWO)\n",
      "    x4 = lbind(recolor, TWO)\n",
      "    x5 = rbind(shoot, DOWN)\n",
      "    x6 = chain(x4, x5, lrcorner)\n",
      "    x7 = lbind(recolor, ONE)\n",
      "    x8 = rbind(shoot, UP_RIGHT)\n",
      "    x9 = chain(x7, x8, urcorner)\n",
      "    x10 = mapply(x6, x2)\n",
      "    x11 = mapply(x9, x3)\n",
      "    x12 = combine(x10, x11)\n",
      "    O = underpaint(I, x12)\n",
      "    return O\n",
      "\n",
      "0.26147469968565545 \n",
      " def solve_86b6403a(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = objects(I, T, F, F)\n",
      "    x2 = mostcolor(I)\n",
      "    x3 = colorfilter(x1, x2)\n",
      "    x4 = fork(equality, toindices, backdrop)\n",
      "    x5 = sfilter(x3, x4)\n",
      "    x6 = lbind(mapply, dneighbors)\n",
      "    x7 = chain(x6, corners, outbox)\n",
      "    x8 = fork(difference, x7, outbox)\n",
      "    x9 = leastcolor(I)\n",
      "    x10 = ofcolor(I, x9)\n",
      "    x11 = rbind(intersection, x10)\n",
      "    x12 = matcher(size, ZERO)\n",
      "    x13 = chain(x12, x11, x8)\n",
      "    x14 = mfilter(x5, x13)\n",
      "    O = fill(I, FOUR, x14)\n",
      "    return O\n",
      "\n",
      "0.3650276645492598 \n",
      " def solve_c2d3777b(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = fgpartition(I)\n",
      "    x2 = merge(x1)\n",
      "    x3 = toindices(x2)\n",
      "    x4 = compose(double, halve)\n",
      "    x5 = fork(equality, identity, x4)\n",
      "    x6 = compose(x5, last)\n",
      "    x7 = sfilter(x3, x6)\n",
      "    x8 = fill(I, EIGHT, x7)\n",
      "    x9 = vmirror(x8)\n",
      "    x10 = ofcolor(x8, ZERO)\n",
      "    O = fill(x8, THREE, x10)\n",
      "    return O\n",
      "\n",
      "0.12581017833567684 \n",
      " def solve_55140364(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = objects(I, T, F, T)\n",
      "    x2 = colorfilter(x1, TWO)\n",
      "    x3 = colorfilter(x1, ONE)\n",
      "    x4 = lbind(recolor, TWO)\n",
      "    x5 = rbind(shoot, UNITY)\n",
      "    x6 = chain(x4, x5, lrcorner)\n",
      "    x7 = lbind(recolor, ONE)\n",
      "    x8 = rbind(shoot, NEG_UNITY)\n",
      "    x9 = chain(x7, x8, ulcorner)\n",
      "    x10 = mapply(x6, x2)\n",
      "    x11 = mapply(x9, x3)\n",
      "    x12 = combine(x10, x11)\n",
      "    O = paint(I, x12)\n",
      "    return O\n",
      "\n",
      "0.26147469968565545 \n",
      " def solve_5d319d33(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = objects(I, T, F, F)\n",
      "    x2 = mostcolor(I)\n",
      "    x3 = colorfilter(x1, x2)\n",
      "    x4 = fork(equality, toindices, backdrop)\n",
      "    x5 = sfilter(x3, x4)\n",
      "    x6 = lbind(mapply, dneighbors)\n",
      "    x7 = chain(x6, corners, outbox)\n",
      "    x8 = fork(difference, x7, outbox)\n",
      "    x9 = leastcolor(I)\n",
      "    x10 = ofcolor(I, x9)\n",
      "    x11 = rbind(intersection, x10)\n",
      "    x12 = matcher(size, ZERO)\n",
      "    x13 = chain(x12, x11, x8)\n",
      "    x14 = mfilter(x5, x13)\n",
      "    O = fill(I, FOUR, x14)\n",
      "    return O\n",
      "\n",
      "0.26147469968565545 \n",
      " def solve_c850edea(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = objects(I, T, F, F)\n",
      "    x2 = mostcolor(I)\n",
      "    x3 = colorfilter(x1, x2)\n",
      "    x4 = fork(equality, toindices, backdrop)\n",
      "    x5 = sfilter(x3, x4)\n",
      "    x6 = lbind(mapply, dneighbors)\n",
      "    x7 = chain(x6, corners, outbox)\n",
      "    x8 = fork(difference, x7, outbox)\n",
      "    x9 = leastcolor(I)\n",
      "    x10 = ofcolor(I, x9)\n",
      "    x11 = rbind(intersection, x10)\n",
      "    x12 = matcher(size, ZERO)\n",
      "    x13 = chain(x12, x11, x8)\n",
      "    x14 = mfilter(x5, x13)\n",
      "    O = fill(I, FOUR, x14)\n",
      "    return O\n",
      "\n",
      "0.09617932940310235 \n",
      " def solve_e4d4de6e(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = fgpartition(I)\n",
      "    x2 = merge(x1)\n",
      "    x3 = center(x2)\n",
      "    x4 = dneighbors(x3)\n",
      "    x5 = insert(x3, x4)\n",
      "    O = fill(I, THREE, x5)\n",
      "    return O\n",
      "\n",
      "0.29310876589370266 \n",
      " def solve_4e4a41a2(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = fgpartition(I)\n",
      "    x2 = merge(x1)\n",
      "    x3 = mostcolor(I)\n",
      "    x4 = fill(I, x3, x2)\n",
      "    x5 = shift(x2, DOWN)\n",
      "    O = fill(x4, TWO, x5)\n",
      "    return O\n",
      "\n",
      "0.36861214897799227 \n",
      " def solve_4da62e60(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = objects(I, T, F, F)\n",
      "    x2 = fork(multiply, height, width)\n",
      "    x3 = argmax(x1, x2)\n",
      "    x4 = remove(x3, x1)\n",
      "    x5 = merge(x4)\n",
      "    x6 = subgrid(x5, I)\n",
      "    x7 = mostcolor(x6)\n",
      "    x8 = leastcolor(x6)\n",
      "    O = switch(x6, x7, x8)\n",
      "    return O\n",
      "\n",
      "0.2667732786862824 \n",
      " def solve_aaba6b11(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = fgpartition(I)\n",
      "    x2 = merge(x1)\n",
      "    x3 = toindices(x2)\n",
      "    x4 = shift(x3, DOWN)\n",
      "    x5 = fill(I, EIGHT, x4)\n",
      "    x6 = shift(x3, RIGHT)\n",
      "    x7 = fill(x5, TWO, x6)\n",
      "    x8 = shift(x3, LEFT)\n",
      "    x9 = fill(x7, SIX, x8)\n",
      "    x10 = shift(x3, DOWN)\n",
      "    x11 = fill(x9, SEVEN, x10)\n",
      "    x12 = shift(x3, RIGHT)\n",
      "    x13 = fill(x11, EIGHT, x12)\n",
      "    x14 = shift(x3, LEFT)\n",
      "    x15 = fill(x13, SEVEN, x14)\n",
      "    x16 = shift(x3, DOWN)\n",
      "    x17 = fill(x15, EIGHT, x16)\n",
      "    x18 = shift(x3, UNITY)\n",
      "    O = fill(x17, SEVEN, x18)\n",
      "    return O\n",
      "\n",
      "0.10830729281693237 \n",
      " def solve_42eaa7a5(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = objects(I, T, F, T)\n",
      "    x2 = sizefilter(x1, TWO)\n",
      "    x3 = mapply(outbox, x2)\n",
      "    O = fill(I, THREE, x3)\n",
      "    return O\n",
      "\n",
      "0.12581017833567684 \n",
      " def solve_6f4fafa6(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = objects(I, T, F, T)\n",
      "    x2 = rbind(greater, TWO)\n",
      "    x3 = chain(x2, minimum, shape)\n",
      "    x4 = fork(equality, toindices, box)\n",
      "    x5 = fork(both, x3, x4)\n",
      "    x6 = mfilter(x1, x5)\n",
      "    O = fill(I, THREE, x6)\n",
      "    return O\n",
      "\n",
      "0.26147469968565545 \n",
      " def solve_93eefb69(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = objects(I, T, F, F)\n",
      "    x2 = mostcolor(I)\n",
      "    x3 = colorfilter(x1, x2)\n",
      "    x4 = fork(equality, toindices, backdrop)\n",
      "    x5 = sfilter(x3, x4)\n",
      "    x6 = lbind(mapply, dneighbors)\n",
      "    x7 = chain(x6, corners, outbox)\n",
      "    x8 = fork(difference, x7, outbox)\n",
      "    x9 = leastcolor(I)\n",
      "    x10 = ofcolor(I, x9)\n",
      "    x11 = rbind(intersection, x10)\n",
      "    x12 = matcher(size, ZERO)\n",
      "    x13 = chain(x12, x11, x8)\n",
      "    x14 = mfilter(x5, x13)\n",
      "    O = fill(I, FOUR, x14)\n",
      "    return O\n",
      "\n",
      "0.26147469968565545 \n",
      " def solve_13786774(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = objects(I, T, F, F)\n",
      "    x2 = mostcolor(I)\n",
      "    x3 = colorfilter(x1, x2)\n",
      "    x4 = fork(equality, toindices, backdrop)\n",
      "    x5 = sfilter(x3, x4)\n",
      "    x6 = lbind(mapply, dneighbors)\n",
      "    x7 = chain(x6, corners, outbox)\n",
      "    x8 = fork(difference, x7, outbox)\n",
      "    x9 = leastcolor(I)\n",
      "    x10 = ofcolor(I, x9)\n",
      "    x11 = rbind(intersection, x10)\n",
      "    x12 = matcher(size, ZERO)\n",
      "    x13 = chain(x12, x11, x8)\n",
      "    x14 = mfilter(x5, x13)\n",
      "    O = fill(I, FOUR, x14)\n",
      "    return O\n",
      "\n",
      "0.25464015450133604 \n",
      " def solve_8113dab3(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = lbind(ofcolor, I)\n",
      "    x2 = lbind(mapply, neighbors)\n",
      "    x3 = chain(x2, x1, last)\n",
      "    x4 = fork(recolor, first, x3)\n",
      "    x5 = astuple(SIX, THREE)\n",
      "    x6 = astuple(FOUR, EIGHT)\n",
      "    x7 = astuple(ONE, TWO)\n",
      "    x8 = initset(x5)\n",
      "    x9 = insert(x6, x8)\n",
      "    x10 = insert(x7, x9)\n",
      "    x11 = mapply(x4, x10)\n",
      "    O = underpaint(I, x11)\n",
      "    return O\n",
      "\n",
      "0.4521855666908194 \n",
      " def solve_99817739(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = frontiers(I)\n",
      "    x2 = sfilter(x1, hline)\n",
      "    x3 = size(x2)\n",
      "    x4 = positive(x3)\n",
      "    x5 = branch(x4, tophalf, lefthalf)\n",
      "    x6 = branch(x4, bottomhalf, righthalf)\n",
      "    x7 = x5(I)\n",
      "    x8 = x6(I)\n",
      "    x9 = palette(x7)\n",
      "    x10 = palette(x8)\n",
      "    x11 = intersection(x9, x10)\n",
      "    x12 = first(x11)\n",
      "    x13 = shape(x7)\n",
      "    x14 = canvas(x12, x13)\n",
      "    x15 = palette(x7)\n",
      "    x16 = other(x15, x12)\n",
      "    x17 = palette(x8)\n",
      "    x18 = other(x17, x12)\n",
      "    x19 = ofcolor(x7, x16)\n",
      "    x20 = ofcolor(x8, x18)\n",
      "    x21 = combine(x19, x20)\n",
      "    O = fill(x14, THREE, x21)\n",
      "    return O\n",
      "\n",
      "0.24111676145747532 \n",
      " def solve_bffc588a(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = objects(I, T, F, F)\n",
      "    x2 = fork(equality, toindices, backdrop)\n",
      "    x3 = compose(flip, x2)\n",
      "    x4 = extract(x1, x3)\n",
      "    x5 = color(x4)\n",
      "    x6 = matcher(color, x5)\n",
      "    x7 = compose(flip, x6)\n",
      "    x8 = sfilter(x1, x7)\n",
      "    x9 = merge(x8)\n",
      "    x10 = fill(I, TWO, x9)\n",
      "    x11 = mapply(box, x8)\n",
      "    x12 = fill(x10, FOUR, x11)\n",
      "    x13 = mapply(corners, x8)\n",
      "    O = fill(x12, ONE, x13)\n",
      "    return O\n",
      "\n",
      "0.12581017833567684 \n",
      " def solve_d89d67f4(I):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    x1 = objects(I, T, F, F)\n",
      "    x2 = sfilter(x1, square)\n",
      "    x3 = compose(even, height)\n",
      "    x4 = sfilter(x2, x3)\n",
      "    x5 = difference(x2, x4)\n",
      "    x6 = merge(x4)\n",
      "    x7 = merge(x5)\n",
      "    x8 = fill(I, TWO, x6)\n",
      "    O = fill(x8, SEVEN, x7)\n",
      "    return O\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p_name, score in scores.items():\n",
    "    if score is not None and score < 0.5:\n",
    "        prog_dict[p_name].update_docstring(\"\")\n",
    "        print(score, \"\\n\", prog_dict[p_name])\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5fdeac20-711b-46fe-be5e-82972c4e9efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(non_null_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f7ebf5de-db13-4b86-b141-3516cc26b85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05a7bcf2'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c457866-7106-4d50-81a9-9f048e46f815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
